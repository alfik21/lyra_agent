import time
import requests
import json

def run_benchmark(model_name, prompt="Opisz w 100 sÅ‚owach przyszÅ‚oÅ›Ä‡ sztucznej inteligencji."):
    print(f"ğŸš€ Start Benchmarku dla modelu: {model_name}")
    print("â³ Generowanie... (To moÅ¼e chwilÄ™ potrwaÄ‡)")
    
    start_time = time.time()
    
    try:
        response = requests.post('http://localhost:11434/api/generate',
            json={
                "model": model_name,
                "prompt": prompt,
                "stream": False
            },
            timeout=120
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        result = response.json()
        text = result.get('response', '')
        # Liczymy tokeny (uproszczone: 1 token ok. 4 znaki)
        token_count = len(text.split()) * 1.3 
        tps = token_count / duration
        
        print("\n" + "="*40)
        print(f"ğŸ“Š WYNIKI DLA {model_name}:")
        print(f"â±ï¸ Czas caÅ‚kowity: {duration:.2d}s")
        print(f"âš¡ PrÄ™dkoÅ›Ä‡: {tps:.2f} tokenÃ³w/sek")
        print(f"ğŸ“ DÅ‚ugoÅ›Ä‡ odpowiedzi: {len(text.split())} sÅ‚Ã³w")
        print("="*40)
        
        return tps
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d benchmarku: {e}")
        return 0

if __name__ == "__main__":
    # Testujemy Bielika na Twoich dwÃ³ch Radeonach
    run_benchmark("Bielik-11B-v2.3-Instruct-EF16-OF16.Q8_0")
